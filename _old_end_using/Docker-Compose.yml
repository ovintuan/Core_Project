# version: "3.8"

services:

  spark-master:
    image: pyspark_workspace:latest
    # build:
    #   context: .
    #   dockerfile: pyspark_workspace.Dockerfile
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8080:8080"  # Spark Web UI
      - "7077:7077"  # Spark Master Port
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080    
    volumes:
      - spark_master_opt_java:/opt/bitnami/java
      - .:/container/pyspark_workspace
    networks:
      - pyspark_workspace_network

  spark-worker-1:
    image: pyspark_workspace:latest
    # build:
    #   context: .
    #   dockerfile: pyspark_workspace.Dockerfile
    container_name: spark-worker-1
    env_file:
      - path: ./config_env_variables/spark_worker.env
    environment:      
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8081      
    volumes:
      - .:/container/pyspark_workspace
    depends_on:
      - spark-master
    networks:
      - pyspark_workspace_network

  spark-worker-2:
    image: pyspark_workspace:latest
    # build:
    #   context: .
    #   dockerfile: pyspark_workspace.Dockerfile
    container_name: spark-worker-2   
    env_file:
      - path: ./config_env_variables/spark_worker.env
    environment:      
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8082 
    volumes:
      - .:/container/pyspark_workspace
    depends_on:
      - spark-master
    networks:
      - pyspark_workspace_network

  python_environment:
    image: python:3.11.9
    user: root
    stdin_open: true  # Keep STDIN open even if not attached
    tty: true         # Allocate a pseudo-TTY 
    environment:
      - JAVA_HOME=/spark_opt_java/
    volumes:
      - spark_master_opt_java:/spark_opt_java/
      - python_site_packages:/usr/local/lib/python3.11/site-packages
      - .:/container/pyspark_workspace  
    depends_on:
      - spark-master
    networks:
      - pyspark_workspace_network

  postgres_database_1:
    image: postgres:latest
    env_file:
      - path: ./config_env_variables/postgres.env
    ports:
      - "3000:5432"
    volumes:
      - ./local_data_storage/postgres:/var/lib/postgresql/data
    networks:
      - pyspark_workspace_network

  sqlserver_database_1:
    image: mcr.microsoft.com/mssql/server:2022-latest
    user: root
    env_file:
      - path: ./config_env_variables/sqlserver1.env
    environment:
      - ACCEPT_EULA=Y
    ports:
      - "1000:1433"
    volumes:
      - ./local_data_storage/sql_server_1:/var/opt/mssql/data
    networks:
      - pyspark_workspace_network

  sqlserver_database_2:
    image: mcr.microsoft.com/mssql/server:2022-latest
    user: root
    env_file:
      - path: ./config_env_variables/sqlserver2.env
    environment:
      - ACCEPT_EULA=Y
    ports:
      - "2000:1433"
    volumes:
      - ./local_data_storage/sql_server_2:/var/opt/mssql/data
    networks:
      - pyspark_workspace_network

volumes:
  spark_master_opt_java:
  python_site_packages:

networks:
  pyspark_workspace_network:

