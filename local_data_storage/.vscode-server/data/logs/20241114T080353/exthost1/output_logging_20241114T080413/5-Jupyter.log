Visual Studio Code (1.95.2, attached-container, desktop)
Jupyter Extension Version: 2024.10.0.
Python Extension Version: 2024.20.0.
Pylance Extension Version: 2024.11.1.
Platform: linux (x64).
Temp Storage folder ~/.vscode-server/data/User/globalStorage/ms-toolsai.jupyter/version-2024.10.0
Workspace folder /container/pyspark_workspace, Home = /root
08:05:24.025 [info] Starting Kernel (Python Path: /usr/local/bin/python, Unknown, 3.11.9) for '/container/pyspark_workspace/source_code/sample_code/Test_Kafka.ipynb' (disableUI=true)
08:05:29.706 [warn] Failed to get activated env vars for /usr/local/bin/python in 5684ms
08:05:29.749 [warn] Failed to get activated env vars for /usr/local/bin/python in 3263ms
08:05:30.483 [info] Process Execution: /usr/local/bin/python -c "import site;print("USER_BASE_VALUE");print(site.USER_BASE);print("USER_BASE_VALUE");"
08:05:30.895 [info] Process Execution: /usr/local/bin/python -m pip list
08:05:30.915 [info] Process Execution: /usr/local/bin/python -c "import ipykernel; print(ipykernel.__version__); print("5dc3a68c-e34e-4080-9c3e-2a532b2ccb4d"); print(ipykernel.__file__)"
08:05:31.850 [warn] Failed to get activated env vars for /usr/local/bin/python in 828ms
08:05:31.877 [info] Process Execution: /usr/local/bin/python -m ipykernel_launcher --f=/~/.local/share/jupyter/runtime/kernel-v3a477c188e7c5826b65882ddd9a7f297e43c4dbe7.json
    > cwd: //container/pyspark_workspace/source_code/sample_code
08:05:33.790 [warn] Disposing old controller startUsingPythonInterpreter:'.jvsc74a57bd06699b966c21a81be21759e40053de52c009daad87cbe5a3dc643468ce4ab3367.d:\Program Files\Python\python.exe.d:\Program Files\Python\python.exe.-m#ipykernel_launcher' for view = 'jupyter-notebook'
08:05:33.793 [warn] Disposing old controller startUsingPythonInterpreter:'.jvsc74a57bd06699b966c21a81be21759e40053de52c009daad87cbe5a3dc643468ce4ab3367.d:\Program Files\Python\python.exe.d:\Program Files\Python\python.exe.-m#ipykernel_launcher (Interactive)' for view = 'interactive'
08:05:47.782 [info] Kernel successfully started
08:05:48.265 [warn] Failed to get activated env vars for /usr/local/bin/python in 412ms
08:05:48.313 [info] Process Execution: /usr/local/bin/python /~/.vscode-server/extensions/ms-toolsai.jupyter-2024.10.0-linux-x64/pythonFiles/printJupyterDataDir.py
08:27:01.747 [info] Interrupt kernel execution
08:27:01.751 [info] Interrupt requested /container/pyspark_workspace/source_code/sample_code/Test_Kafka.ipynb
08:27:01.777 [info] Interrupt kernel execution
08:27:01.778 [info] Interrupting kernel: python3119jvsc74a57bd0949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1
08:27:01.781 [info] Interrupting kernel via SIGINT
08:27:03.856 [warn] Cell completed with errors (cancelled)
08:27:03.863 [warn] Cancel all remaining cells due to cancellation or failure in execution
08:27:03.870 [info] Interrupt requested & sent for /container/pyspark_workspace/source_code/sample_code/Test_Kafka.ipynb in notebookEditor.
08:30:39.126 [warn] Cell completed with errors iu [Error]: Queries with streaming sources must be executed with writeStream.start();
kafka
    at n.execute (/~/.vscode-server/extensions/ms-toolsai.jupyter-2024.10.0-linux-x64/dist/extension.node.js:297:4958) {
  ename: 'AnalysisException',
  evalue: 'Queries with streaming sources must be executed with writeStream.start();\n' +
    'kafka',
  traceback: [
    '\x1B[0;31m---------------------------------------------------------------------------\x1B[0m',
    '\x1B[0;31mAnalysisException\x1B[0m                         Traceback (most recent call last)',
    'Cell \x1B[0;32mIn[14], line 17\x1B[0m\n' +
      '\x1B[1;32m      1\x1B[0m df \x1B[38;5;241m=\x1B[39m spark \\\n' +
      '\x1B[1;32m      2\x1B[0m     \x1B[38;5;241m.\x1B[39mreadStream \\\n' +
      '\x1B[1;32m      3\x1B[0m     \x1B[38;5;241m.\x1B[39mformat(\x1B[38;5;124m"\x1B[39m\x1B[38;5;124mkafka\x1B[39m\x1B[38;5;124m"\x1B[39m) \\\n' +
      '\x1B[0;32m   (...)\x1B[0m\n' +
      '\x1B[1;32m      6\x1B[0m     \x1B[38;5;241m.\x1B[39moption(\x1B[38;5;124m"\x1B[39m\x1B[38;5;124mstartingOffsets\x1B[39m\x1B[38;5;124m"\x1B[39m, \x1B[38;5;124m"\x1B[39m\x1B[38;5;124mearliest\x1B[39m\x1B[38;5;124m"\x1B[39m) \\\n' +
      '\x1B[1;32m      7\x1B[0m     \x1B[38;5;241m.\x1B[39mload()\n' +
      '\x1B[1;32m      9\x1B[0m \x1B[38;5;66;03m# Start the streaming query and display results\x1B[39;00m\n' +
      '\x1B[1;32m     10\x1B[0m \x1B[38;5;66;03m# query = df.writeStream \\\x1B[39;00m\n' +
      '\x1B[1;32m     11\x1B[0m \x1B[38;5;66;03m#     .outputMode("append") \\\x1B[39;00m\n' +
      '\x1B[0;32m   (...)\x1B[0m\n' +
      '\x1B[1;32m     14\x1B[0m \n' +
      '\x1B[1;32m     15\x1B[0m \x1B[38;5;66;03m# query.awaitTermination()\x1B[39;00m\n' +
      '\x1B[0;32m---> 17\x1B[0m \x1B[43mdf\x1B[49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43mtoPandas\x1B[49m\x1B[43m(\x1B[49m\x1B[43m)\x1B[49m\n',
    'File \x1B[0;32m/usr/local/lib/python3.11/site-packages/pyspark/sql/pandas/conversion.py:202\x1B[0m, in \x1B[0;36mPandasConversionMixin.toPandas\x1B[0;34m(self)\x1B[0m\n' +
      '\x1B[1;32m    199\x1B[0m             \x1B[38;5;28;01mraise\x1B[39;00m\n' +
      '\x1B[1;32m    201\x1B[0m \x1B[38;5;66;03m# Below is toPandas without Arrow optimization.\x1B[39;00m\n' +
      '\x1B[0;32m--> 202\x1B[0m rows \x1B[38;5;241m=\x1B[39m \x1B[38;5;28;43mself\x1B[39;49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43mcollect\x1B[49m\x1B[43m(\x1B[49m\x1B[43m)\x1B[49m\n' +
      '\x1B[1;32m    203\x1B[0m \x1B[38;5;28;01mif\x1B[39;00m \x1B[38;5;28mlen\x1B[39m(rows) \x1B[38;5;241m>\x1B[39m \x1B[38;5;241m0\x1B[39m:\n' +
      '\x1B[1;32m    204\x1B[0m     pdf \x1B[38;5;241m=\x1B[39m pd\x1B[38;5;241m.\x1B[39mDataFrame\x1B[38;5;241m.\x1B[39mfrom_records(\n' +
      '\x1B[1;32m    205\x1B[0m         rows, index\x1B[38;5;241m=\x1B[39m\x1B[38;5;28mrange\x1B[39m(\x1B[38;5;28mlen\x1B[39m(rows)), columns\x1B[38;5;241m=\x1B[39m\x1B[38;5;28mself\x1B[39m\x1B[38;5;241m.\x1B[39mcolumns  \x1B[38;5;66;03m# type: ignore[arg-type]\x1B[39;00m\n' +
      '\x1B[1;32m    206\x1B[0m     )\n',
    'File \x1B[0;32m/usr/local/lib/python3.11/site-packages/pyspark/sql/dataframe.py:1263\x1B[0m, in \x1B[0;36mDataFrame.collect\x1B[0;34m(self)\x1B[0m\n' +
      '\x1B[1;32m   1243\x1B[0m \x1B[38;5;250m\x1B[39m\x1B[38;5;124;03m"""Returns all the records as a list of :class:`Row`.\x1B[39;00m\n' +
      '\x1B[1;32m   1244\x1B[0m \n' +
      '\x1B[1;32m   1245\x1B[0m \x1B[38;5;124;03m.. versionadded:: 1.3.0\x1B[39;00m\n' +
      '\x1B[0;32m   (...)\x1B[0m\n' +
      "\x1B[1;32m   1260\x1B[0m \x1B[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\x1B[39;00m\n" +
      '\x1B[1;32m   1261\x1B[0m \x1B[38;5;124;03m"""\x1B[39;00m\n' +
      '\x1B[1;32m   1262\x1B[0m \x1B[38;5;28;01mwith\x1B[39;00m SCCallSiteSync(\x1B[38;5;28mself\x1B[39m\x1B[38;5;241m.\x1B[39m_sc):\n' +
      '\x1B[0;32m-> 1263\x1B[0m     sock_info \x1B[38;5;241m=\x1B[39m \x1B[38;5;28;43mself\x1B[39;49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43m_jdf\x1B[49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43mcollectToPython\x1B[49m\x1B[43m(\x1B[49m\x1B[43m)\x1B[49m\n' +
      '\x1B[1;32m   1264\x1B[0m \x1B[38;5;28;01mreturn\x1B[39;00m \x1B[38;5;28mlist\x1B[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n',
    'File \x1B[0;32m/usr/local/lib/python3.11/site-packages/py4j/java_gateway.py:1322\x1B[0m, in \x1B[0;36mJavaMember.__call__\x1B[0;34m(self, *args)\x1B[0m\n' +
      '\x1B[1;32m   1316\x1B[0m command \x1B[38;5;241m=\x1B[39m proto\x1B[38;5;241m.\x1B[39mCALL_COMMAND_NAME \x1B[38;5;241m+\x1B[39m\\\n' +
      '\x1B[1;32m   1317\x1B[0m     \x1B[38;5;28mself\x1B[39m\x1B[38;5;241m.\x1B[39mcommand_header \x1B[38;5;241m+\x1B[39m\\\n' +
      '\x1B[1;32m   1318\x1B[0m     args_command \x1B[38;5;241m+\x1B[39m\\\n' +
      '\x1B[1;32m   1319\x1B[0m     proto\x1B[38;5;241m.\x1B[39mEND_COMMAND_PART\n' +
      '\x1B[1;32m   1321\x1B[0m answer \x1B[38;5;241m=\x1B[39m \x1B[38;5;28mself\x1B[39m\x1B[38;5;241m.\x1B[39mgateway_client\x1B[38;5;241m.\x1B[39msend_command(command)\n' +
      '\x1B[0;32m-> 1322\x1B[0m return_value \x1B[38;5;241m=\x1B[39m \x1B[43mget_return_value\x1B[49m\x1B[43m(\x1B[49m\n' +
      '\x1B[1;32m   1323\x1B[0m \x1B[43m    \x1B[49m\x1B[43manswer\x1B[49m\x1B[43m,\x1B[49m\x1B[43m \x1B[49m\x1B[38;5;28;43mself\x1B[39;49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43mgateway_client\x1B[49m\x1B[43m,\x1B[49m\x1B[43m \x1B[49m\x1B[38;5;28;43mself\x1B[39;49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43mtarget_id\x1B[49m\x1B[43m,\x1B[49m\x1B[43m \x1B[49m\x1B[38;5;28;43mself\x1B[39;49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43mname\x1B[49m\x1B[43m)\x1B[49m\n' +
      '\x1B[1;32m   1325\x1B[0m \x1B[38;5;28;01mfor\x1B[39;00m temp_arg \x1B[38;5;129;01min\x1B[39;00m temp_args:\n' +
      '\x1B[1;32m   1326\x1B[0m     \x1B[38;5;28;01mif\x1B[39;00m \x1B[38;5;28mhasattr\x1B[39m(temp_arg, \x1B[38;5;124m"\x1B[39m\x1B[38;5;124m_detach\x1B[39m\x1B[38;5;124m"\x1B[39m):\n',
    'File \x1B[0;32m/usr/local/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:185\x1B[0m, in \x1B[0;36mcapture_sql_exception.<locals>.deco\x1B[0;34m(*a, **kw)\x1B[0m\n' +
      '\x1B[1;32m    181\x1B[0m converted \x1B[38;5;241m=\x1B[39m convert_exception(e\x1B[38;5;241m.\x1B[39mjava_exception)\n' +
      '\x1B[1;32m    182\x1B[0m \x1B[38;5;28;01mif\x1B[39;00m \x1B[38;5;129;01mnot\x1B[39;00m \x1B[38;5;28misinstance\x1B[39m(converted, UnknownException):\n' +
      '\x1B[1;32m    183\x1B[0m     \x1B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\x1B[39;00m\n' +
      '\x1B[1;32m    184\x1B[0m     \x1B[38;5;66;03m# JVM exception message.\x1B[39;00m\n' +
      '\x1B[0;32m--> 185\x1B[0m     \x1B[38;5;28;01mraise\x1B[39;00m converted \x1B[38;5;28;01mfrom\x1B[39;00m \x1B[38;5;28;01mNone\x1B[39;00m\n' +
      '\x1B[1;32m    186\x1B[0m \x1B[38;5;28;01melse\x1B[39;00m:\n' +
      '\x1B[1;32m    187\x1B[0m     \x1B[38;5;28;01mraise\x1B[39;00m\n',
    '\x1B[0;31mAnalysisException\x1B[0m: Queries with streaming sources must be executed with writeStream.start();\n' +
      'kafka'
  ]
}
08:30:52.841 [warn] Cell completed with errors iu [Error]: Queries with streaming sources must be executed with writeStream.start();
kafka
    at n.execute (/~/.vscode-server/extensions/ms-toolsai.jupyter-2024.10.0-linux-x64/dist/extension.node.js:297:4958) {
  ename: 'AnalysisException',
  evalue: 'Queries with streaming sources must be executed with writeStream.start();\n' +
    'kafka',
  traceback: [
    '\x1B[0;31m---------------------------------------------------------------------------\x1B[0m',
    '\x1B[0;31mAnalysisException\x1B[0m                         Traceback (most recent call last)',
    'Cell \x1B[0;32mIn[15], line 17\x1B[0m\n' +
      '\x1B[1;32m      1\x1B[0m df \x1B[38;5;241m=\x1B[39m spark \\\n' +
      '\x1B[1;32m      2\x1B[0m     \x1B[38;5;241m.\x1B[39mreadStream \\\n' +
      '\x1B[1;32m      3\x1B[0m     \x1B[38;5;241m.\x1B[39mformat(\x1B[38;5;124m"\x1B[39m\x1B[38;5;124mkafka\x1B[39m\x1B[38;5;124m"\x1B[39m) \\\n' +
      '\x1B[0;32m   (...)\x1B[0m\n' +
      '\x1B[1;32m      6\x1B[0m     \x1B[38;5;241m.\x1B[39moption(\x1B[38;5;124m"\x1B[39m\x1B[38;5;124mstartingOffsets\x1B[39m\x1B[38;5;124m"\x1B[39m, \x1B[38;5;124m"\x1B[39m\x1B[38;5;124mearliest\x1B[39m\x1B[38;5;124m"\x1B[39m) \\\n' +
      '\x1B[1;32m      7\x1B[0m     \x1B[38;5;241m.\x1B[39mload()\n' +
      '\x1B[1;32m      9\x1B[0m \x1B[38;5;66;03m# Start the streaming query and display results\x1B[39;00m\n' +
      '\x1B[1;32m     10\x1B[0m \x1B[38;5;66;03m# query = df.writeStream \\\x1B[39;00m\n' +
      '\x1B[1;32m     11\x1B[0m \x1B[38;5;66;03m#     .outputMode("append") \\\x1B[39;00m\n' +
      '\x1B[0;32m   (...)\x1B[0m\n' +
      '\x1B[1;32m     14\x1B[0m \n' +
      '\x1B[1;32m     15\x1B[0m \x1B[38;5;66;03m# query.awaitTermination()\x1B[39;00m\n' +
      '\x1B[0;32m---> 17\x1B[0m \x1B[43mdf\x1B[49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43mshow\x1B[49m\x1B[43m(\x1B[49m\x1B[43m)\x1B[49m\n',
    'File \x1B[0;32m/usr/local/lib/python3.11/site-packages/pyspark/sql/dataframe.py:947\x1B[0m, in \x1B[0;36mDataFrame.show\x1B[0;34m(self, n, truncate, vertical)\x1B[0m\n' +
      '\x1B[1;32m    887\x1B[0m \x1B[38;5;28;01mdef\x1B[39;00m \x1B[38;5;21mshow\x1B[39m(\x1B[38;5;28mself\x1B[39m, n: \x1B[38;5;28mint\x1B[39m \x1B[38;5;241m=\x1B[39m \x1B[38;5;241m20\x1B[39m, truncate: Union[\x1B[38;5;28mbool\x1B[39m, \x1B[38;5;28mint\x1B[39m] \x1B[38;5;241m=\x1B[39m \x1B[38;5;28;01mTrue\x1B[39;00m, vertical: \x1B[38;5;28mbool\x1B[39m \x1B[38;5;241m=\x1B[39m \x1B[38;5;28;01mFalse\x1B[39;00m) \x1B[38;5;241m-\x1B[39m\x1B[38;5;241m>\x1B[39m \x1B[38;5;28;01mNone\x1B[39;00m:\n' +
      '\x1B[1;32m    888\x1B[0m \x1B[38;5;250m    \x1B[39m\x1B[38;5;124;03m"""Prints the first ``n`` rows to the console.\x1B[39;00m\n' +
      '\x1B[1;32m    889\x1B[0m \n' +
      '\x1B[1;32m    890\x1B[0m \x1B[38;5;124;03m    .. versionadded:: 1.3.0\x1B[39;00m\n' +
      '\x1B[0;32m   (...)\x1B[0m\n' +
      '\x1B[1;32m    945\x1B[0m \x1B[38;5;124;03m    name | Bob\x1B[39;00m\n' +
      '\x1B[1;32m    946\x1B[0m \x1B[38;5;124;03m    """\x1B[39;00m\n' +
      '\x1B[0;32m--> 947\x1B[0m     \x1B[38;5;28mprint\x1B[39m(\x1B[38;5;28;43mself\x1B[39;49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43m_show_string\x1B[49m\x1B[43m(\x1B[49m\x1B[43mn\x1B[49m\x1B[43m,\x1B[49m\x1B[43m \x1B[49m\x1B[43mtruncate\x1B[49m\x1B[43m,\x1B[49m\x1B[43m \x1B[49m\x1B[43mvertical\x1B[49m\x1B[43m)\x1B[49m)\n',
    'File \x1B[0;32m/usr/local/lib/python3.11/site-packages/pyspark/sql/dataframe.py:965\x1B[0m, in \x1B[0;36mDataFrame._show_string\x1B[0;34m(self, n, truncate, vertical)\x1B[0m\n' +
      '\x1B[1;32m    959\x1B[0m     \x1B[38;5;28;01mraise\x1B[39;00m PySparkTypeError(\n' +
      '\x1B[1;32m    960\x1B[0m         error_class\x1B[38;5;241m=\x1B[39m\x1B[38;5;124m"\x1B[39m\x1B[38;5;124mNOT_BOOL\x1B[39m\x1B[38;5;124m"\x1B[39m,\n' +
      '\x1B[1;32m    961\x1B[0m         message_parameters\x1B[38;5;241m=\x1B[39m{\x1B[38;5;124m"\x1B[39m\x1B[38;5;124marg_name\x1B[39m\x1B[38;5;124m"\x1B[39m: \x1B[38;5;124m"\x1B[39m\x1B[38;5;124mvertical\x1B[39m\x1B[38;5;124m"\x1B[39m, \x1B[38;5;124m"\x1B[39m\x1B[38;5;124marg_type\x1B[39m\x1B[38;5;124m"\x1B[39m: \x1B[38;5;28mtype\x1B[39m(vertical)\x1B[38;5;241m.\x1B[39m\x1B[38;5;18m__name__\x1B[39m},\n' +
      '\x1B[1;32m    962\x1B[0m     )\n' +
      '\x1B[1;32m    964\x1B[0m \x1B[38;5;28;01mif\x1B[39;00m \x1B[38;5;28misinstance\x1B[39m(truncate, \x1B[38;5;28mbool\x1B[39m) \x1B[38;5;129;01mand\x1B[39;00m truncate:\n' +
      '\x1B[0;32m--> 965\x1B[0m     \x1B[38;5;28;01mreturn\x1B[39;00m \x1B[38;5;28;43mself\x1B[39;49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43m_jdf\x1B[49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43mshowString\x1B[49m\x1B[43m(\x1B[49m\x1B[43mn\x1B[49m\x1B[43m,\x1B[49m\x1B[43m \x1B[49m\x1B[38;5;241;43m20\x1B[39;49m\x1B[43m,\x1B[49m\x1B[43m \x1B[49m\x1B[43mvertical\x1B[49m\x1B[43m)\x1B[49m\n' +
      '\x1B[1;32m    966\x1B[0m \x1B[38;5;28;01melse\x1B[39;00m:\n' +
      '\x1B[1;32m    967\x1B[0m     \x1B[38;5;28;01mtry\x1B[39;00m:\n',
    'File \x1B[0;32m/usr/local/lib/python3.11/site-packages/py4j/java_gateway.py:1322\x1B[0m, in \x1B[0;36mJavaMember.__call__\x1B[0;34m(self, *args)\x1B[0m\n' +
      '\x1B[1;32m   1316\x1B[0m command \x1B[38;5;241m=\x1B[39m proto\x1B[38;5;241m.\x1B[39mCALL_COMMAND_NAME \x1B[38;5;241m+\x1B[39m\\\n' +
      '\x1B[1;32m   1317\x1B[0m     \x1B[38;5;28mself\x1B[39m\x1B[38;5;241m.\x1B[39mcommand_header \x1B[38;5;241m+\x1B[39m\\\n' +
      '\x1B[1;32m   1318\x1B[0m     args_command \x1B[38;5;241m+\x1B[39m\\\n' +
      '\x1B[1;32m   1319\x1B[0m     proto\x1B[38;5;241m.\x1B[39mEND_COMMAND_PART\n' +
      '\x1B[1;32m   1321\x1B[0m answer \x1B[38;5;241m=\x1B[39m \x1B[38;5;28mself\x1B[39m\x1B[38;5;241m.\x1B[39mgateway_client\x1B[38;5;241m.\x1B[39msend_command(command)\n' +
      '\x1B[0;32m-> 1322\x1B[0m return_value \x1B[38;5;241m=\x1B[39m \x1B[43mget_return_value\x1B[49m\x1B[43m(\x1B[49m\n' +
      '\x1B[1;32m   1323\x1B[0m \x1B[43m    \x1B[49m\x1B[43manswer\x1B[49m\x1B[43m,\x1B[49m\x1B[43m \x1B[49m\x1B[38;5;28;43mself\x1B[39;49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43mgateway_client\x1B[49m\x1B[43m,\x1B[49m\x1B[43m \x1B[49m\x1B[38;5;28;43mself\x1B[39;49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43mtarget_id\x1B[49m\x1B[43m,\x1B[49m\x1B[43m \x1B[49m\x1B[38;5;28;43mself\x1B[39;49m\x1B[38;5;241;43m.\x1B[39;49m\x1B[43mname\x1B[49m\x1B[43m)\x1B[49m\n' +
      '\x1B[1;32m   1325\x1B[0m \x1B[38;5;28;01mfor\x1B[39;00m temp_arg \x1B[38;5;129;01min\x1B[39;00m temp_args:\n' +
      '\x1B[1;32m   1326\x1B[0m     \x1B[38;5;28;01mif\x1B[39;00m \x1B[38;5;28mhasattr\x1B[39m(temp_arg, \x1B[38;5;124m"\x1B[39m\x1B[38;5;124m_detach\x1B[39m\x1B[38;5;124m"\x1B[39m):\n',
    'File \x1B[0;32m/usr/local/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:185\x1B[0m, in \x1B[0;36mcapture_sql_exception.<locals>.deco\x1B[0;34m(*a, **kw)\x1B[0m\n' +
      '\x1B[1;32m    181\x1B[0m converted \x1B[38;5;241m=\x1B[39m convert_exception(e\x1B[38;5;241m.\x1B[39mjava_exception)\n' +
      '\x1B[1;32m    182\x1B[0m \x1B[38;5;28;01mif\x1B[39;00m \x1B[38;5;129;01mnot\x1B[39;00m \x1B[38;5;28misinstance\x1B[39m(converted, UnknownException):\n' +
      '\x1B[1;32m    183\x1B[0m     \x1B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\x1B[39;00m\n' +
      '\x1B[1;32m    184\x1B[0m     \x1B[38;5;66;03m# JVM exception message.\x1B[39;00m\n' +
      '\x1B[0;32m--> 185\x1B[0m     \x1B[38;5;28;01mraise\x1B[39;00m converted \x1B[38;5;28;01mfrom\x1B[39;00m \x1B[38;5;28;01mNone\x1B[39;00m\n' +
      '\x1B[1;32m    186\x1B[0m \x1B[38;5;28;01melse\x1B[39;00m:\n' +
      '\x1B[1;32m    187\x1B[0m     \x1B[38;5;28;01mraise\x1B[39;00m\n',
    '\x1B[0;31mAnalysisException\x1B[0m: Queries with streaming sources must be executed with writeStream.start();\n' +
      'kafka'
  ]
}
10:29:22.907 [warn] Cell completed with errors iu [Error]: unexpected character after line continuation character (1958155979.py, line 12)
    at n.execute (/~/.vscode-server/extensions/ms-toolsai.jupyter-2024.10.0-linux-x64/dist/extension.node.js:297:4958) {
  ename: 'SyntaxError',
  evalue: 'unexpected character after line continuation character (1958155979.py, line 12)',
  traceback: [
    '\x1B[0;36m  Cell \x1B[0;32mIn[20], line 12\x1B[0;36m\x1B[0m\n' +
      '\x1B[0;31m    .format("console") \\\x1B[0m\n' +
      '\x1B[0m                          \n' +
      '^\x1B[0m\n' +
      '\x1B[0;31mSyntaxError\x1B[0m\x1B[0;31m:\x1B[0m unexpected character after line continuation character\n'
  ]
}
10:29:34.086 [warn] Cell completed with errors iu [Error]: unexpected character after line continuation character (222699815.py, line 12)
    at n.execute (/~/.vscode-server/extensions/ms-toolsai.jupyter-2024.10.0-linux-x64/dist/extension.node.js:297:4958) {
  ename: 'SyntaxError',
  evalue: 'unexpected character after line continuation character (222699815.py, line 12)',
  traceback: [
    '\x1B[0;36m  Cell \x1B[0;32mIn[21], line 12\x1B[0;36m\x1B[0m\n' +
      '\x1B[0;31m    .format("console") \\\x1B[0m\n' +
      '\x1B[0m                          \n' +
      '^\x1B[0m\n' +
      '\x1B[0;31mSyntaxError\x1B[0m\x1B[0;31m:\x1B[0m unexpected character after line continuation character\n'
  ]
}
10:31:01.711 [info] Interrupt kernel execution
10:31:01.711 [info] Interrupt requested /container/pyspark_workspace/source_code/sample_code/Test_Kafka.ipynb
10:31:01.712 [info] Interrupt kernel execution
10:31:01.712 [info] Interrupting kernel: python3119jvsc74a57bd0949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1
10:31:01.713 [info] Interrupting kernel via SIGINT
10:31:02.176 [warn] Cell completed with errors (cancelled)
10:31:02.190 [info] Interrupt requested & sent for /container/pyspark_workspace/source_code/sample_code/Test_Kafka.ipynb in notebookEditor.
10:31:23.264 [info] Interrupt kernel execution
10:31:23.264 [info] Interrupt requested /container/pyspark_workspace/source_code/sample_code/Test_Kafka.ipynb
10:31:23.265 [info] Interrupt kernel execution
10:31:23.265 [info] Interrupting kernel: python3119jvsc74a57bd0949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1
10:31:23.265 [info] Interrupting kernel via SIGINT
10:31:23.440 [warn] Cell completed with errors (cancelled)
10:31:23.448 [info] Interrupt requested & sent for /container/pyspark_workspace/source_code/sample_code/Test_Kafka.ipynb in notebookEditor.
